{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 20:56:18.233207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.265147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.265386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from layer.bayesian_dropout_layer import BayesianDropoutLayer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"/home/fsantiago/projects/medium/datasets/cifar-10/train_aug\"\n",
    "train_labels = \"/home/fsantiago/projects/medium/datasets/cifar-10/labels_aug.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(train_labels, index_col=\"id\")\n",
    "one_hot = OneHotEncoder().fit(labels_df[[\"label\"]])\n",
    "one_hot_labels = OneHotEncoder().fit_transform(labels_df[[\"label\"]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 20:56:18.545081: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-02 20:56:18.546141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.546499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.546790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.935661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.935869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.936038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 20:56:18.936183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2885 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960, pci bus id: 0000:06:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "auto_input = layers.Input(shape=(32, 32, 3))\n",
    "layer_1 = BayesianDropoutLayer(units=512, dropout=0.1, activation=tf.nn.relu)\n",
    "layer_2 = BayesianDropoutLayer(units=512, dropout=0.1, activation=tf.nn.relu)\n",
    "layer_3 = BayesianDropoutLayer(units=128, dropout=0.1, activation=tf.nn.relu)\n",
    "\n",
    "def get_conv_layer(filters, x, dropout=0.25, kernel_size=(3, 3)):\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def get_conv_layer_2(filters, x, number_of_layers):\n",
    "\n",
    "    for i in range(number_of_layers - 1):\n",
    "        x = layers.Conv2D(filters, kernel_size=(3,3), padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3,3), strides=(2, 2), padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_mini_vgg_19():\n",
    "\n",
    "    x = get_conv_layer(32, auto_input, kernel_size=(3, 3))\n",
    "    x = get_conv_layer(32, x, kernel_size=(3, 3))\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = get_conv_layer(64, x)\n",
    "    x = get_conv_layer(64, x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = get_conv_layer(128, x)\n",
    "    x = get_conv_layer(128, x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # x = layer_1(x)\n",
    "    # x = layer_2(x)\n",
    "    # x = layer_3(x)\n",
    "\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_mini_plain():\n",
    "\n",
    "    x = get_conv_layer(64, auto_input, 3)\n",
    "    x = get_conv_layer(128, x, 4)\n",
    "    x = get_conv_layer(256, x, 6)\n",
    "    x = get_conv_layer(512, x, 2)\n",
    "\n",
    "    x = layers.AveragePooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(1000, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "x = get_mini_vgg_19()\n",
    "model = Model(auto_input, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f9cec48a910> and <keras.layers.core.dropout.Dropout object at 0x7f9cec48a9d0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f9cec494dc0> and <keras.layers.core.dense.Dense object at 0x7f9cec48a910>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.core.dense.Dense object at 0x7f9cec494bb0> and <keras.layers.core.dropout.Dropout object at 0x7f9cec494430>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [00:46<00:00, 6413.39it/s]\n"
     ]
    }
   ],
   "source": [
    "test_folder = \"/home/fsantiago/projects/medium/datasets/cifar-10/test/test/\"\n",
    "model.load_weights(\"./bayesian_weigths/weights.ckpt\")\n",
    "\n",
    "img_number = 300000\n",
    "files_index = list(range(1, img_number + 1))\n",
    "test_labels_df = pd.DataFrame()\n",
    "imgs = []\n",
    "\n",
    "for file_idx in tqdm(files_index):\n",
    "    file = f\"{test_folder}{file_idx}.png\"\n",
    "    img = plt.imread(file)\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    x = get_mini_vgg_19()\n",
    "    model = Model(auto_input, x)\n",
    "    model.load_weights(\"./normal_nn_weigths/weights.ckpt\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_predictions(one_hot, i, imgs, chunk):\n",
    "    model = load_model()\n",
    "    preds_onehot = model(np.array(imgs[i*chunk:(i+1)*chunk]))\n",
    "    preds = [pred[0] for pred in one_hot.inverse_transform(preds_onehot)]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [24:37<00:00, 14.78s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "chunk = 3000\n",
    "reps = int(300000 / chunk) \n",
    "bayesian_reps = 1\n",
    "test_labels_df = pd.DataFrame()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "for i in tqdm(range(reps)):    \n",
    "    bayesian_predictions = []\n",
    "    for j in range(bayesian_reps):\n",
    "        preds = get_predictions(one_hot, i, imgs, chunk)     \n",
    "        bayesian_predictions.append(preds)\n",
    "        del(preds)\n",
    "        gc.collect()\n",
    "\n",
    "    bayesian_predictions = np.array(bayesian_predictions).T\n",
    "\n",
    "    for bay_i in range(len(bayesian_predictions)):\n",
    "        preds = dict(Counter(bayesian_predictions[bay_i]))\n",
    "        key = max(preds, key=preds.get)\n",
    "        probability = preds[key]/bayesian_reps\n",
    "\n",
    "        new_label = {\"id\": [i*chunk + bay_i + 1] ,\n",
    "                     \"label\": [key], \"prob\": [probability]}\n",
    "        new_row = pd.DataFrame.from_records(new_label, index=\"id\")\n",
    "        test_labels_df = pd.concat([test_labels_df, new_row])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df.to_csv(\"bayesian_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_df[\"prob\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df[\"label\"].to_csv(\"results_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce992e2e1cfe1b7012fa6e861a47a87ef8e8a57e529bf8108b5368176a26c139"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
