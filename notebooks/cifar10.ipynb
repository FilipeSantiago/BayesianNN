{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:14:50.741857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:14:50.775501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:14:50.775718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from layer.bayesian_dropout_layer import BayesianDropoutLayer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"/home/fsantiago/projects/medium/datasets/cifar-10/train_aug\"\n",
    "train_labels = \"/home/fsantiago/projects/medium/datasets/cifar-10/labels_aug.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(train_labels, index_col=\"id\")\n",
    "one_hot = OneHotEncoder().fit(labels_df[[\"label\"]])\n",
    "one_hot_labels = OneHotEncoder().fit_transform(labels_df[[\"label\"]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(file):\n",
    "    file_idx = int(file.replace(\".png\", \"\")) - 1\n",
    "\n",
    "    return one_hot_labels[file_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(train_folder)\n",
    "files_batch = files.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149695"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 120000\n",
    "validation_size = 10000\n",
    "test_size = 19695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [f\"{val_file}.png\" for  val_file in list(range(1, validation_size))]\n",
    "val_files = [f\"{val_file}.png\" for  val_file in list(range(validation_size+1, test_size))]\n",
    "train_files = [f\"{val_file}.png\" for  val_file in list(range(test_size+1, train_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [plt.imread(f\"{train_folder}/{file}\") for file in train_files]\n",
    "train_y = [get_y(file) for file in train_files]\n",
    "\n",
    "validation_X = [plt.imread(f\"{train_folder}/{file}\") for file in val_files]\n",
    "validation_y = [get_y(file) for file in val_files]\n",
    "\n",
    "test_X = [plt.imread(f\"{train_folder}/{file}\") for file in test_files]\n",
    "test_y = [get_y(file) for file in test_files]\n",
    "\n",
    "train_mean = np.array([train.mean() for train in train_X]).mean()\n",
    "\n",
    "train_X = [img[...,:, :3] - train_mean for img in train_X]\n",
    "validation_X = [img[...,:, :3] - train_mean for img in validation_X]\n",
    "test_X = [img[...,:, :3] - train_mean for img in test_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def load_batches_img_folder(folder_path, train_size, batch_size):\n",
    "\n",
    "    files = os.listdir(folder_path)[:train_size]\n",
    "    files_batch = files.copy()\n",
    "    batches = []\n",
    "\n",
    "    while len(files_batch) > 0:\n",
    "        if len(files_batch) < batch_size:\n",
    "            batch = files_batch.copy()\n",
    "        else:\n",
    "            batch = random.sample(files_batch, batch_size)\n",
    "\n",
    "        files_batch = list(filter(lambda x: x not in batch, files_batch))\n",
    "        batches.append(batch)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "\n",
    "def load_batches(folder_path, train_size, batch_size, train_mean):\n",
    "    file_batches = load_batches_img_folder(folder_path, train_size, batch_size)\n",
    "    batches = []\n",
    "\n",
    "    for batch_files in file_batches:\n",
    "        batch = []\n",
    "        y = []\n",
    "        for file in batch_files:\n",
    "            img = plt.imread(f\"{folder_path}/{file}\", format=\"png\") - train_mean\n",
    "            y.append(get_y(file))\n",
    "            if img.shape[2] != 3:\n",
    "                img = img[...,:, :3]\n",
    "\n",
    "            batch.append(img)\n",
    "        \n",
    "        batches.append((np.array(batch), y))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = load_batches(train_folder, train_size, batch_size, train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:08:47.983488: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-03 11:08:47.984305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:08:47.984634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:08:47.984824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:08:48.321345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:08:48.321561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:08:48.321733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-03 11:08:48.321883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2977 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960, pci bus id: 0000:06:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " bayesian_dropout_layer (Bay  (None, 4096)             8392704   \n",
      " esianDropoutLayer)                                              \n",
      "                                                                 \n",
      " bayesian_dropout_layer_1 (B  (None, 4096)             16781312  \n",
      " ayesianDropoutLayer)                                            \n",
      "                                                                 \n",
      " bayesian_dropout_layer_2 (B  (None, 1000)             4097000   \n",
      " ayesianDropoutLayer)                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,880,002\n",
      "Trainable params: 39,873,090\n",
      "Non-trainable params: 6,912\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:08:48.688337: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "auto_input = layers.Input(shape=(32, 32, 3))\n",
    "layer_1 = BayesianDropoutLayer(units=1024, dropout=0.2, l=1e-3, activation=tf.nn.relu)\n",
    "layer_2 = BayesianDropoutLayer(units=1024, dropout=0.2, l=1e-3, activation=tf.nn.relu)\n",
    "layer_3 = BayesianDropoutLayer(units=250, dropout=0.2, l=1e-3, activation=tf.nn.relu)\n",
    "\n",
    "def get_conv_layer(filters, x, dropout=0.25, kernel_size=(3, 3)):\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def get_conv_layer_2(filters, x, number_of_layers):\n",
    "\n",
    "    for i in range(number_of_layers - 1):\n",
    "        x = layers.Conv2D(filters, kernel_size=(3,3), padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size=(3,3), strides=(2, 2), padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_mini_vgg_19():\n",
    "\n",
    "    x = get_conv_layer(64, auto_input, kernel_size=(3, 3))\n",
    "    x = get_conv_layer(64, x, kernel_size=(3, 3))\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = get_conv_layer(128, x)\n",
    "    x = get_conv_layer(128, x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = get_conv_layer(256, x)\n",
    "    x = get_conv_layer(256, x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = get_conv_layer(512, x)\n",
    "    x = get_conv_layer(512, x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layer_1(x)\n",
    "    x = layer_2(x)\n",
    "    x = layer_3(x)\n",
    "\n",
    "    # x = layers.Dense(512, activation='relu')(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    # x = layers.Dense(512, activation='relu')(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    # x = layers.Dense(128, activation='relu')(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_mini_plain():\n",
    "\n",
    "    x = get_conv_layer(64, auto_input, 3)\n",
    "    x = get_conv_layer(128, x, 4)\n",
    "    x = get_conv_layer(256, x, 6)\n",
    "    x = get_conv_layer(512, x, 2)\n",
    "\n",
    "    x = layers.AveragePooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(1000, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "x = get_mini_vgg_19()\n",
    "model = Model(auto_input, x)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "def compute_loss(labels, logits):\n",
    "    loss = tf.keras.losses.categorical_crossentropy(labels, logits)\n",
    "\n",
    "    regularization =  (layer_1.regularization + layer_2.regularization + layer_3.regularization)\n",
    "    loss = loss + regularization\n",
    "\n",
    "    return loss, regularization\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y): \n",
    "    # Use tf.GradientTape()\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        y_hat = model(x)      \n",
    "        loss, regularization = compute_loss(y, y_hat)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
    "               \n",
    "        return loss, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:08:50.777495: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8300\n",
      "2022-04-03 11:08:51.131432: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-03 11:08:52.033026: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-03 11:08:52.146867: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-03 11:08:52.612357: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-03 11:08:52.833884: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-03 11:08:53.659431: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-04-03 11:13:16.378384: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-03 11:13:16.734779: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 40 => time:268.97793316841125 loss:2.303684949874878, reg:0.00031900580506771803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/fsantiago/projects/medium/bayesiandropout/notebooks/cifar10.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fsantiago/projects/medium/bayesiandropout/notebooks/cifar10.ipynb#ch0000016?line=10'>11</a>\u001b[0m     x_batch, y_batch \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fsantiago/projects/medium/bayesiandropout/notebooks/cifar10.ipynb#ch0000016?line=11'>12</a>\u001b[0m     x_batch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x_batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fsantiago/projects/medium/bayesiandropout/notebooks/cifar10.ipynb#ch0000016?line=12'>13</a>\u001b[0m     loss, regularization \u001b[39m=\u001b[39m train_step(x_batch, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fsantiago/projects/medium/bayesiandropout/notebooks/cifar10.ipynb#ch0000016?line=14'>15</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fsantiago/projects/medium/bayesiandropout/notebooks/cifar10.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m => time:\u001b[39m\u001b[39m{\u001b[39;00mend_time \u001b[39m-\u001b[39m start_time\u001b[39m}\u001b[39;00m\u001b[39m loss:\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39marray(loss)\u001b[39m.\u001b[39mmean()\u001b[39m}\u001b[39;00m\u001b[39m, reg:\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39marray(regularization)\u001b[39m.\u001b[39mmean()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2955\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2951'>2952</a>\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m-> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3244\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3219'>3220</a>\u001b[0m \u001b[39m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3220'>3221</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3221'>3222</a>\u001b[0m \u001b[39m`args` and `kwargs` can be None if this `Function` was created with an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3239'>3240</a>\u001b[0m \u001b[39m    shape relaxation retracing.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3240'>3241</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3241'>3242</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3242'>3243</a>\u001b[0m   args, kwargs, flat_args, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m-> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3243'>3244</a>\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_spec\u001b[39m.\u001b[39;49mcanonicalize_function_inputs(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3244'>3245</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=3245'>3246</a>\u001b[0m   flat_args, filtered_flat_args \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m], []\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2766\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2762'>2763</a>\u001b[0m       kwargs\u001b[39m.\u001b[39msetdefault(kwarg, default)\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2764'>2765</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2765'>2766</a>\u001b[0m   inputs, flat_inputs, filtered_flat_inputs \u001b[39m=\u001b[39m _convert_numpy_inputs(inputs)\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2766'>2767</a>\u001b[0m   kwargs, flat_kwargs, filtered_flat_kwargs \u001b[39m=\u001b[39m _convert_numpy_inputs(kwargs)\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2767'>2768</a>\u001b[0m   flat_inputs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_kwargs\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2806\u001b[0m, in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2802'>2803</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(a, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2803'>2804</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe output of __array__ must be an np.ndarray, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2804'>2805</a>\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(a)\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2805'>2806</a>\u001b[0m flat_inputs[index] \u001b[39m=\u001b[39m constant_op\u001b[39m.\u001b[39;49mconstant(a)\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2806'>2807</a>\u001b[0m filtered_flat_inputs\u001b[39m.\u001b[39mappend(flat_inputs[index])\n\u001b[1;32m   <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2807'>2808</a>\u001b[0m need_packing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=169'>170</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=170'>171</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=171'>172</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=172'>173</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=173'>174</a>\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=264'>265</a>\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=265'>266</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=266'>267</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=267'>268</a>\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=276'>277</a>\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=277'>278</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=278'>279</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=280'>281</a>\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=281'>282</a>\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=301'>302</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=302'>303</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=303'>304</a>\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=304'>305</a>\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=305'>306</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=99'>100</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=100'>101</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> <a href='file:///home/fsantiago/projects/medium/bayesiandropout/venv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 40\n",
    "_batches = batches\n",
    "print(len(_batches))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in _batches:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch = np.array(x_batch)\n",
    "        loss, regularization = train_step(x_batch, y_batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"{epoch} of {epochs} => time:{end_time - start_time} loss:{np.array(loss).mean()}, reg:{np.array(regularization).mean()}\")\n",
    "\n",
    "    # if epoch % 10 == 0:\n",
    "        \n",
    "    #     val_predictions = model.predict(np.array(validation_X))\n",
    "    #     val_predictions = list(map(lambda x: x[0], one_hot.inverse_transform(val_predictions)))\n",
    "    #     val_labels = list(map(lambda x: x[0], one_hot.inverse_transform(validation_y)))\n",
    "    #     val_acc = accuracy_score(val_labels, val_predictions)\n",
    "\n",
    "    #     print(f\"\\n Val acc: {val_acc} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(np.array(validation_X))\n",
    "val_predictions = list(map(lambda x: x[0], one_hot.inverse_transform(val_predictions)))\n",
    "val_labels = list(map(lambda x: x[0], one_hot.inverse_transform(validation_y)))\n",
    "\n",
    "\n",
    "test_predictions = model.predict(np.array(test_X))\n",
    "test_predictions = list(map(lambda x: x[0], one_hot.inverse_transform(test_predictions)))\n",
    "test_labels = list(map(lambda x: x[0], one_hot.inverse_transform(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0999099909990999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['frog', 'truck', 'deer', 'automobile', 'bird', 'horse', 'ship',\n",
       "       'cat', 'dog', 'airplane'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"label\": test_labels, \"predictions\": test_predictions})\n",
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird   0.0\n",
      "cat   0.0\n",
      "ship   0.0\n",
      "horse   0.0\n",
      "dog   0.0\n",
      "deer   1.0\n",
      "airplane   0.0\n",
      "automobile   0.0\n",
      "frog   0.0\n",
      "truck   0.0\n"
     ]
    }
   ],
   "source": [
    "labels = ['bird', 'cat', 'ship', 'horse', 'dog', 'deer', 'airplane', 'automobile', 'frog', 'truck']\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    df_label = df[df[\"label\"] == label].copy()\n",
    "    acc = accuracy_score(df_label[\"label\"], df_label[\"predictions\"])\n",
    "    print(f\"{label}   {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deer</th>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "predictions       \n",
       "deer          1032"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dog = df[df[\"label\"] == 'bird'].copy()\n",
    "\n",
    "df_dog.groupby(['predictions']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10088714668867341"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(val_labels, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./normal_nn_weigths/weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f31f06672e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folder = \"/home/fsantiago/projects/medium/datasets/cifar-10/test/test/\"\n",
    "model.load_weights(\"./bayesian_weigths/weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
